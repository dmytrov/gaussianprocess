import os
import time
import pickle
import logging
import numpy as np
import dataset.mocap as ds
import numerical.numpyext.logger as npl
import ml.dtw.dynamictimewarp as dtw
import matplotlib.pyplot as plt

def DTW_errors(observed, predicted):
    """
    observed : [T, N] - observed data
    predicted : [T, N] - predicted (generated by a model) data
    """
    N = observed.shape[1]
    var = np.sqrt(np.sum((observed - np.mean(observed, axis=0))**2)) 
    odist, opath = dtw.dynTimeWarp(observed / var, predicted / var, 
            transitions=[(1, 1, 0.0), (0, 1, N*0.0001), (1, 0, N*0.0001)])

    warp_dist_err = odist
    wgen = np.array([predicted[i[0]] for i in opath])
    wtra = np.array([observed[i[1]] for i in opath])
    
    #plt.plot(wtra[:, :3] / var, "--")
    #plt.gca().set_prop_cycle(None)
    #plt.plot(wgen[:, :3] / var)
    #plt.show()
    

    warp_path_mean_sqr_err = np.mean((wgen - wtra)**2)
    return warp_dist_err, warp_path_mean_sqr_err


def compute_errors(observed, predicted):
    """
    observed : [T, N] - observed data
    predicted : [T, N] - predicted (generated by a model) data
    returns : (mse, tre, warp_dyn, warp_lvm)
        mse : mean square error
        warp_dyn : time error of the warping
        warp_lvm : residual error after warping alignment
    """
    #print(observed.shape, predicted.shape)
    o = observed - np.mean(observed, axis=0)
    p = predicted - np.mean(predicted, axis=0)
    mse = np.mean((o - p)**2)
    warp_dyn, warp_path_mean_sqr_er = DTW_errors(o, p)
    errors = {"MSE": mse, 
              "WRAP_DYN": warp_dyn,
              "WRAP_PATH": warp_path_mean_sqr_er}
    return errors


def all_combinations(params):
    if len(params) == 1:
        return [[param] for param in params[0]]
    else:
        return [combination + [param] for combination in all_combinations(params[:-1]) for param in params[-1]]


def all_combinations_from_dict(params):
    return [zip(params.keys(), c) for c in all_combinations(params.values())]

def all_combinations_from_listoftuples(params):
    keys = [key for key, value in params]
    values = [value for key, value in params]
    return [zip(keys, c) for c in all_combinations(values)]


class ModelIterator(object):
    def __init__(self):
        self.recording = None
        self.bodypart_motiontypes = None
        self.partitioner = None
        self.parts_IDs = None
        self.nparts = None
        self.trial = None
        self.settings = {}
        self.params_range = None
        self.directory = time.strftime("%Y-%m-%d-%H.%M.%S")

    def load_recording(self, recording, bodypart_motiontypes, max_chunks=None):
        # Load data
        self.recording = recording
        self.bodypart_motiontypes = bodypart_motiontypes
        self.partitioner, self.parts_IDs, trials, starts_ends = ds.load_recording(
            recording=self.recording,
            bodypart_motiontypes=bodypart_motiontypes,
            max_chunks=max_chunks)
        self.trial = trials[0]
        self.nparts = np.max(self.parts_IDs) + 1

    def iterate_all_settings(self, func_callback, i_model=None):
        # Iterate all settings
        for i, params in enumerate(all_combinations_from_listoftuples(self.params_range)):
            if i_model is None or i_model == i:
                try:
                    if not os.path.exists(self.directory):
                        os.makedirs(self.directory)        
                    self.settings.update(params)
                    self.settings["directory"] = self.directory + "/" + \
                        "-".join(["{}({})".format(param[0], param[1]) for param in params])
                    npl.setup_root_logger(rootlogfilename="{}/rootlog.txt".format(self.directory), removeoldlog=False)
                    pl = logging.getLogger(__name__)
                    pl.info("Working directory: " + self.settings["directory"])
                    func_callback(settings=self.settings,
                            trial=self.trial,
                            bvhpartitioner=self.partitioner)
                except (KeyboardInterrupt, SystemExit):
                    raise
                except Exception as e:
                    npl.setup_root_logger(rootlogfilename="{}/rootlog.txt".format(self.directory), removeoldlog=False)
                    pl = logging.getLogger(__name__)
                    pl.exception(e)


class ErrorStatsReader(object):
    def __init__(self):
        self.errs = []
        self.params_range = None
        self.errorsfilename = "errors.pkl"


    def read_learned_errors_from_file(self, errfilename, param=None):
        try:
            with open(errfilename, "rb") as filehandle:
                e = pickle.load(filehandle)
                if "settings" not in e:
                    e["settings"] = param
            self.errs.append(e)
            print("Loaded {}".format(errfilename))
        except:
            print("Failed to load {}".format(errfilename))


    def read_learned_errors(self, settings, trial, bvhpartitioner=None):
        errfilename = settings["directory"] + "/" + self.errorsfilename
        print("os.getcwd()", os.getcwd())
        self.read_learned_errors_from_file(errfilename)
        

    def to_tensor(self, key, params_range=None, filter=None):
        if params_range is None:
            params_range = self.params_range
        a = np.nan * np.zeros([len(pr) for pn, pr in params_range])

        for s in self.errs:
            try:
                if filter is None or filter(s):
                    inds = tuple((pr.index(s["settings"][pn]) for pn, pr in params_range))
                    a[inds] = s[key]
            except (KeyError, ValueError):
                pass
        return a



def select_by(tensor_axes, tensor_value, params):
    """
    tensor_axes: N*(axisname, M*axisvalue)
    tensor_value: 
    params
    """
    keys = [key for key, value in params]
    values = [value for key, value in params]
    paramsdict = dict(zip(keys, values))
    inds = tuple((pr.index(paramsdict[pn]) if pn in paramsdict else slice(None) for pn, pr in tensor_axes))
    res_axes = [tl for tl in tensor_axes if tl[0] not in paramsdict]
    res_data = tensor_value[inds]
    #res_data = np.squeeze(res_data)  # no need to squeeze?
    return res_axes, res_data


def iterate_by(tensor_axes, tensor_value, iter_params_keys):
    iter_range = [(k, v) for k, v in tensor_axes if k in iter_params_keys]
    iter_combs = all_combinations_from_listoftuples(iter_range)
    for iter_comb in iter_combs:
        res_axes, res_data = select_by(tensor_axes, tensor_value, iter_comb)
        yield iter_comb, res_axes, res_data


def mean_std(tensor_axes, tensor_value, alongs):
    ialong = tuple([[pn for pn, pr in tensor_axes].index(along) for along in alongs])
    return np.nanmean(tensor_value, axis=ialong), np.nanstd(tensor_value, axis=ialong)


def values_by_name(tensor_axes, name):
    keys = [key for key, value in tensor_axes]
    values = [value for key, value in tensor_axes]
    paramsdict = dict(zip(keys, values))
    return paramsdict[name]

